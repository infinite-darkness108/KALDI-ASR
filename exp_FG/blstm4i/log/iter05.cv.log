speech-HP-Z2-Tower-G9
nnet-train-multistream-perutt --cross-validate=true --randomize=false --verbose=0 --num-streams=10 --max-frames=15000 --feature-transform=exp_FG/blstm4i/final.feature_transform 'ark:copy-feats scp:exp_FG/blstm4i/cv.scp ark:- | apply-cmvn --norm-means=true --norm-vars=true --utt2spk=ark:data-fbank/train_cv10/utt2spk scp:data-fbank/train_cv10/cmvn.scp ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |' 'ark:ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl "ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp_FG/blstm4i/nnet/nnet_iter05 
WARNING (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuId():cu-device.cc:243) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:438) Selecting from 1 GPUs
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:453) cudaSetDevice(0): NVIDIA RTX A2000 12GB	free:11515M, used:515M, total:12031M, free/total:0.957153
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:501) Device: 0, mem_ratio: 0.957153
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuId():cu-device.cc:382) Trying to select device: 0
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:511) Success selecting device 0 free mem ratio: 0.957153
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:FinalizeActiveGpu():cu-device.cc:338) The active GPU is [0]: NVIDIA RTX A2000 12GB	free:11106M, used:924M, total:12031M, free/total:0.923168 version 8.6
copy-feats scp:exp_FG/blstm4i/cv.scp ark:- 
apply-cmvn --norm-means=true --norm-vars=true --utt2spk=ark:data-fbank/train_cv10/utt2spk scp:data-fbank/train_cv10/cmvn.scp ark:- ark:- 
add-deltas --delta-order=2 ark:- ark:- 
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:144) CROSS-VALIDATION STARTED
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:Read():nnet/nnet-matrix-buffer.h:191) Read() started... Buffer size in MB: 0, max 3072, having 0 utterances.
ali-to-post ark:- ark:- 
ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl 'ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |' ark:- 
LOG (copy-feats[5.5.1074~1-71f3]:main():copy-feats.cc:143) Copied 296 feature matrices.
LOG (apply-cmvn[5.5.1074~1-71f3]:main():apply-cmvn.cc:159) Applied cepstral mean and variance normalization to 296 utterances, errors on 0
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:303) ### After 0 frames,
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:304) num-components 4
input-dim 78
output-dim 1280
number-of-parameters 2.04864 millions
component 1 : <BlstmProjected>, input-dim 78, output-dim 640, cell-dim 2x320 ( learn_rate_coef_ 1, bias_learn_rate_coef_ 1, cell_clip_ 50, diff_clip_ 1, grad_clip_ 250 )
  Forward Direction weights:
  f_w_gifo_x_   ( min -0.534412, max 0.575167, mean 0.00392646, stddev 0.0828441, skewness 0.0129826, kurtosis 0.451696 ) 
  f_w_gifo_r_   ( min -0.396732, max 0.402796, mean -0.000584577, stddev 0.0776614, skewness -0.00137377, kurtosis 0.00726247 ) 
  f_bias_   ( min -0.351988, max 1.33522, mean 0.213059, stddev 0.460789, skewness 1.06584, kurtosis -0.65511 ) 
  f_peephole_i_c_   ( min -0.481604, max 0.485605, mean -0.00317217, stddev 0.126939, skewness 0.119733, kurtosis 1.24239 ) 
  f_peephole_f_c_   ( min -0.697312, max 0.899064, mean 0.00409983, stddev 0.167501, skewness 0.433853, kurtosis 5.04795 ) 
  f_peephole_o_c_   ( min -0.499965, max 0.483306, mean -0.0107627, stddev 0.182714, skewness 0.172178, kurtosis -0.27957 ) 
  f_w_r_m_   ( min -0.544066, max 0.502354, mean 0.000607742, stddev 0.101407, skewness 0.00228731, kurtosis -0.00437164 ) 
  Backward Direction weights:
  b_w_gifo_x_   ( min -1.27296, max 0.911836, mean 0.00641885, stddev 0.0886868, skewness -0.099603, kurtosis 2.71066 ) 
  b_w_gifo_r_   ( min -0.36186, max 0.308144, mean -0.000210136, stddev 0.0702765, skewness 8.17872e-05, kurtosis -0.310479 ) 
  b_bias_   ( min -0.342501, max 1.19224, mean 0.206842, stddev 0.451399, skewness 1.04729, kurtosis -0.689132 ) 
  b_peephole_i_c_   ( min -0.351871, max 0.292619, mean 0.00521996, stddev 0.0943552, skewness -0.111132, kurtosis 0.931633 ) 
  b_peephole_f_c_   ( min -0.668495, max 0.697546, mean 0.0114531, stddev 0.164035, skewness 0.464016, kurtosis 3.8556 ) 
  b_peephole_o_c_   ( min -0.549219, max 0.494779, mean -0.0164459, stddev 0.18734, skewness -0.131944, kurtosis 0.207577 ) 
  b_w_r_m_   ( min -0.405403, max 0.363496, mean -0.00025552, stddev 0.0899801, skewness -0.000330038, kurtosis -0.0753531 ) 
component 2 : <Tanh>, input-dim 640, output-dim 640, 
component 3 : <AffineTransform>, input-dim 640, output-dim 1280, 
  linearity ( min -0.925742, max 0.71254, mean -0.000155919, stddev 0.106477, skewness 0.00606121, kurtosis 0.0643852 ) , lr-coef 1, max-norm 0
  bias ( min -0.0827118, max 2.31625, mean 9.31323e-10, stddev 0.0762138, skewness 23.0727, kurtosis 672.905 ) , lr-coef 1
component 4 : <Softmax>, input-dim 1280, output-dim 1280, 

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:305) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -11.004, max 12.2048, mean 0.00682255, stddev 0.969149, skewness 0.287893, kurtosis 3.83541 ) 
[1] output of <BlstmProjected> ( min -4.01055, max 4.09604, mean -0.000523878, stddev 0.753372, skewness 0.00291282, kurtosis 0.933871 ) 
[2] output of <Tanh> ( min -0.999343, max 0.999446, mean -0.000264625, stddev 0.512854, skewness -0.0029093, kurtosis -0.820557 ) 
[3] output of <AffineTransform> ( min -13.9831, max 18.9599, mean 0.0102781, stddev 2.36091, skewness 0.679875, kurtosis 2.1664 ) 
[4] output of <Softmax> ( min 1.31846e-12, max 0.99875, mean 0.00077995, stddev 0.0162211, skewness 38.3098, kurtosis 1725.56 ) 
### END FORWARD

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:334) ### After 79212 frames,
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:335) num-components 4
input-dim 78
output-dim 1280
number-of-parameters 2.04864 millions
component 1 : <BlstmProjected>, input-dim 78, output-dim 640, cell-dim 2x320 ( learn_rate_coef_ 1, bias_learn_rate_coef_ 1, cell_clip_ 50, diff_clip_ 1, grad_clip_ 250 )
  Forward Direction weights:
  f_w_gifo_x_   ( min -0.534412, max 0.575167, mean 0.00392646, stddev 0.0828441, skewness 0.0129826, kurtosis 0.451696 ) 
  f_w_gifo_r_   ( min -0.396732, max 0.402796, mean -0.000584577, stddev 0.0776614, skewness -0.00137377, kurtosis 0.00726247 ) 
  f_bias_   ( min -0.351988, max 1.33522, mean 0.213059, stddev 0.460789, skewness 1.06584, kurtosis -0.65511 ) 
  f_peephole_i_c_   ( min -0.481604, max 0.485605, mean -0.00317217, stddev 0.126939, skewness 0.119733, kurtosis 1.24239 ) 
  f_peephole_f_c_   ( min -0.697312, max 0.899064, mean 0.00409983, stddev 0.167501, skewness 0.433853, kurtosis 5.04795 ) 
  f_peephole_o_c_   ( min -0.499965, max 0.483306, mean -0.0107627, stddev 0.182714, skewness 0.172178, kurtosis -0.27957 ) 
  f_w_r_m_   ( min -0.544066, max 0.502354, mean 0.000607742, stddev 0.101407, skewness 0.00228731, kurtosis -0.00437164 ) 
  Backward Direction weights:
  b_w_gifo_x_   ( min -1.27296, max 0.911836, mean 0.00641885, stddev 0.0886868, skewness -0.099603, kurtosis 2.71066 ) 
  b_w_gifo_r_   ( min -0.36186, max 0.308144, mean -0.000210136, stddev 0.0702765, skewness 8.17872e-05, kurtosis -0.310479 ) 
  b_bias_   ( min -0.342501, max 1.19224, mean 0.206842, stddev 0.451399, skewness 1.04729, kurtosis -0.689132 ) 
  b_peephole_i_c_   ( min -0.351871, max 0.292619, mean 0.00521996, stddev 0.0943552, skewness -0.111132, kurtosis 0.931633 ) 
  b_peephole_f_c_   ( min -0.668495, max 0.697546, mean 0.0114531, stddev 0.164035, skewness 0.464016, kurtosis 3.8556 ) 
  b_peephole_o_c_   ( min -0.549219, max 0.494779, mean -0.0164459, stddev 0.18734, skewness -0.131944, kurtosis 0.207577 ) 
  b_w_r_m_   ( min -0.405403, max 0.363496, mean -0.00025552, stddev 0.0899801, skewness -0.000330038, kurtosis -0.0753531 ) 
component 2 : <Tanh>, input-dim 640, output-dim 640, 
component 3 : <AffineTransform>, input-dim 640, output-dim 1280, 
  linearity ( min -0.925742, max 0.71254, mean -0.000155919, stddev 0.106477, skewness 0.00606121, kurtosis 0.0643852 ) , lr-coef 1, max-norm 0
  bias ( min -0.0827118, max 2.31625, mean 9.31323e-10, stddev 0.0762138, skewness 23.0727, kurtosis 672.905 ) , lr-coef 1
component 4 : <Softmax>, input-dim 1280, output-dim 1280, 

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:336) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.66434, max 7.26584, mean -0.0147177, stddev 0.961893, skewness 0.577064, kurtosis 2.62679 ) 
[1] output of <BlstmProjected> ( min -4.24915, max 4.54615, mean -0.00146303, stddev 0.709796, skewness -0.0213088, kurtosis 1.71873 ) 
[2] output of <Tanh> ( min -0.999592, max 0.999775, mean -0.00018879, stddev 0.47896, skewness -0.00989506, kurtosis -0.516304 ) 
[3] output of <AffineTransform> ( min -12.4748, max 20.1428, mean 0.0148721, stddev 2.24606, skewness 0.81325, kurtosis 3.34546 ) 
[4] output of <Softmax> ( min 9.174e-13, max 0.992758, mean 0.000780849, stddev 0.0185038, skewness 37.1638, kurtosis 1565.57 ) 
### END FORWARD

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:346) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 1670 30 8 79 45 6 24 17 70 220 22 36 34 39 10 53 43 120 22 20 34 66 38 35 87 73 52 35 43 17 86 33 19 32 16 75 106 10 5 1873 21251 22 63 135 22 30 80 98 44 43 9 67 66 27 41 51 107 54 285 40 48 24 308 222 21 35 16 33 248 15 54 49 139 81 14 4 45 35 47 26 17 66 4 14 44 25 18 49 111 11 94 64 72 34 66 27 32 33 78 42 15 34 9 135 37 103 31 64 37 21 67 0 93 69 23 2 34 10 32 37 25 34 18 19 28 43 46 13 4 26 88 25 22 43 33 62 12 98 32 25 22 78 11 62 24 13 88 37 45 30 117 35 60 38 37 129 16 23 64 982 29 24 10 20 31 33 34 16 52 44 64 25 22 25 3 9 30 11 42 35 13 12 11 8 32 32 9 20 32 48 32 42 56 36 35 41 27 16 5 29 35 31 12 7 9 45 27 81 21 16 19 72 29 0 46 70 68 37 26 33 50 37 32 9 5 26 23 15 14 128 52 51 59 20 20 8 73 5 17 32 22 16 4 39 60 11 16 7 19 20 8 7 52 22 37 15 32 12 39 94 72 13 59 17 69 35 25 11 13 18 58 26 24 119 16 14 9 5 13 35 18 40 17 83 10 20 20 32 21 19 33 104 48 60 79 47 20 14 27 49 56 7 20 34 199 37 4 3 21 22 15 27 39 6 10 11 22 25 47 21 6 14 6 60 3 43 26 14 8 10 70 4 15 29 11 133 11 35 22 51 21 57 14 109 15 36 29 5 21 20 18 19 114 55 69 35 21 21 64 44 39 43 15 21 37 31 46 70 32 25 50 48 101 37 32 62 34 53 184 59 33 24 47 16 35 9 79 14 45 12 20 16 36 46 8 52 28 13 12 31 17 29 40 53 13 20 9 73 85 128 108 21 7 44 30 32 12 46 15 32 90 31 20 32 52 21 237 45 11 21 215 49 25 30 31 29 71 13 57 48 98 46 27 41 19 60 21 4 38 48 50 5 63 71 0 0 25 47 11 16 42 44 49 71 27 15 49 22 22 11 30 67 41 56 15 28 24 35 7 14 15 34 7 8 38 0 9 28 57 50 12 13 39 28 40 746 35 13 19 19 18 27 12 16 52 60 21 82 1 33 49 89 6 38 42 18 51 39 26 11 19 7 23 28 18 51 98 35 37 10 34 11 56 273 7 39 31 18 21 15 24 22 15 25 6 21 53 59 24 25 15 4 49 28 14 9 8 3 8 29 34 0 8 18 51 52 48 23 3 60 16 24 35 46 16 52 37 72 3 38 59 15 5 40 14 54 52 32 51 4 14 21 187 40 33 16 15 18 19 52 32 28 37 29 41 52 10 6 95 18 46 53 17 8 5 18 31 15 14 27 7 8 17 7 93 28 14 64 22 15 8 48 40 29 32 15 10 26 38 92 13 54 242 3 84 0 22 55 226 137 6 121 19 57 20 16 55 85 4 17 33 53 42 81 83 26 30 36 55 64 9 66 84 47 14 13 91 43 19 13 23 37 17 19 27 24 0 59 88 26 15 20 111 16 50 7 32 22 5 17 15 28 38 22 27 28 48 52 41 28 16 114 105 37 112 43 4 69 17 87 95 11 45 15 22 24 24 65 3 27 29 73 63 47 17 34 18 53 17 37 17 20 6 14 36 78 20 8 14 23 47 6 6 22 3 11 89 3 5 18 20 146 25 8 25 44 29 28 22 26 34 24 73 34 85 42 37 35 79 40 39 34 32 23 18 104 65 9 45 19 21 17 48 42 21 40 28 25 27 73 23 34 2 186 119 39 90 27 23 23 38 48 0 28 66 71 45 13 24 7 25 19 16 23 24 129 50 34 21 69 32 14 26 16 14 79 10 15 35 83 24 21 61 28 128 42 66 19 12 25 28 26 60 26 36 30 128 60 8 15 24 59 47 2 19 63 42 22 4 29 30 49 65 12 8 20 32 71 48 32 17 59 28 24 21 20 22 26 24 15 35 0 17 35 13 29 14 47 49 7 13 6 17 31 19 38 15 53 143 34 68 37 23 6 34 29 7 46 92 30 48 31 3 30 16 40 24 44 69 43 19 65 170 29 5 28 134 73 20 11 82 86 29 13 21 12 10 24 12 81 163 12 193 6 28 39 45 31 23 36 65 11 39 113 30 11 28 125 45 52 34 87 20 29 16 97 42 97 26 45 39 15 109 53 18 59 52 33 29 52 31 45 25 45 136 11 24 33 61 26 28 29 106 30 33 18 48 56 86 92 23 37 23 14 2 14 36 346 138 60 357 25 129 51 39 29 11 53 15 14 13 44 38 41 41 8 18 32 16 20 21 17 8 96 16 23 156 45 91 21 6 43 48 25 45 29 8 22 23 31 42 3 198 10 14 29 25 39 64 39 11 26 28 39 96 13 53 5 34 9 11 21 67 28 24 50 19 10 11 22 23 15 13 30 30 176 37 84 80 124 21 74 32 81 43 23 25 68 52 83 27 20 0 33 56 14 23 30 22 132 113 9 71 18 15 16 5 38 61 32 70 35 44 36 82 12 19 25 56 12 24 164 178 24 42 24 19 11 41 67 112 11 27 62 39 5 26 82 58 18 39 25 15 60 20 122 54 35 24 51 28 24 13 180 152 39 59 14 42 123 70 441 14 35 36 425 22 33 13 41 32 48 41 161 16 18 110 56 36 262 66 33 47 21 15 29 84 58 48 47 2 22 14 22 35 120 98 20 59 274 17 15 22 15 59 16 0 27 31 40 47 63 69 16 68 32 39 426 46 55 29 28 47 14 42 42 14 17 28 110 23 16 27 12 36 25 38 21 57 45 37 40 25 7 21 46 54 29 44 49 16 46 13 48 16 103 37 35 12 34 ]
@@@ Loss per-class: [ 0.691266 1.47606 1.58828 1.83127 1.51782 2.52953 1.63565 0.873017 2.61118 1.91924 2.61947 2.87826 0.79141 2.2058 1.89356 3.21346 1.72576 3.64483 4.59247 0.773187 1.65621 2.02509 4.24117 1.54036 1.60086 2.17759 1.97339 4.51799 1.79194 1.22764 5.02824 4.78799 1.49038 3.721 0.318166 0.541812 2.55785 1.29158 4.42031 0.874051 1.33163 3.5589 4.00344 1.44611 2.04274 2.572 2.45706 6.42113 1.42961 1.07182 2.18682 2.71577 2.02022 3.01732 1.16632 1.7305 1.73102 0.524225 0.877235 1.50395 3.30983 1.96799 0.467799 2.07196 3.66299 2.13601 1.81733 2.91991 1.00564 2.06971 1.38901 1.93388 1.9479 1.41734 0.962145 1.5315 2.69255 0.351192 1.87037 0.909646 1.88434 2.29715 4.27774 0.986774 1.49192 2.06116 2.79927 2.81901 2.33599 1.9089 2.8521 0.625048 1.85077 2.51407 4.5696 4.63686 0.709651 1.96558 1.94301 0.829958 4.28847 2.59005 3.61049 1.81224 0.64332 3.95322 2.304 1.95634 2.47418 1.43003 2.29528 0 3.15944 1.49623 1.34653 2.83812 1.96139 1.56487 2.01351 2.53555 2.2015 4.12257 2.04435 1.7278 0.713339 2.04803 2.83977 2.98897 0.540744 1.03826 1.20678 1.75609 1.44795 2.27555 2.69641 1.11569 1.7644 0.530517 2.12142 2.7587 3.63019 1.27567 1.27922 2.15007 3.49792 0.615305 1.91962 2.84921 2.01536 1.45753 1.14252 2.11349 2.86592 1.68197 1.79851 0.409323 1.10518 1.88118 1.51323 2.99289 1.5993 1.96201 2.83117 5.7902 1.2612 2.87592 2.23653 2.00566 0.878058 3.58631 1.05936 2.61101 2.11694 2.41935 3.90842 0.972049 1.61368 1.65981 2.61059 3.16407 1.52896 1.82754 6.68963 1.20651 1.69621 1.69965 1.84846 1.87756 1.35955 2.73881 1.18998 2.43363 1.94247 2.11084 1.19992 1.10212 2.46915 3.01748 2.18681 0.873457 2.64046 2.88296 1.49572 2.05056 2.76708 1.41798 2.34421 1.34865 2.35212 2.33805 1.84829 2.0058 0.883337 0 2.98428 1.08073 2.42346 1.61712 2.18529 1.4146 2.2969 2.0411 1.91475 1.2587 2.38437 2.35223 4.31806 3.29349 0.882657 3.04628 2.1449 1.90554 1.99061 1.86264 5.11652 3.25973 1.38746 2.93082 1.96978 1.04934 5.09765 1.51367 2.93021 0.97125 3.23533 4.27385 1.54559 5.19419 2.38326 3.42046 3.17958 1.86099 3.0605 1.05744 2.73753 0.945966 1.18808 0.772571 2.31349 0.593211 1.4712 1.63741 2.39673 1.73633 2.28117 0.24209 2.2537 1.30362 0.720296 1.56586 2.6487 1.18049 4.40063 3.3135 2.0743 3.58148 0.431614 4.36196 1.28011 1.76221 1.11594 2.29622 1.16238 3.75597 1.42575 1.81597 0.762439 1.07659 8.86269 1.33988 1.52724 2.00111 1.74844 0.399031 4.09897 3.00334 1.14976 2.07953 4.16347 5.62413 1.62973 1.87035 2.31029 2.77519 0.377435 0.804236 4.69952 1.5984 3.16804 4.68424 1.42201 1.84328 1.98359 0.806339 4.589 2.97054 3.28305 1.66575 2.03379 4.96346 3.86776 1.35827 3.75988 0.553933 2.85439 2.89265 3.01273 4.3103 2.0374 1.79089 1.64302 1.80095 2.10045 1.81083 0.790512 1.8185 2.64869 2.16433 1.88694 2.50151 1.55193 1.09336 1.72627 1.51532 2.96773 2.8473 1.685 2.49482 0.993238 3.00728 3.21949 2.04149 1.10001 0.730179 2.11454 2.09082 1.94879 2.55966 3.0274 2.33664 1.05589 3.25489 2.67356 2.13389 1.23185 4.55764 1.12267 1.34054 2.11257 2.73872 2.90949 2.15802 1.23931 2.00071 0.633924 0.691795 1.05277 1.00289 2.51338 2.20156 2.29977 1.98764 0.584573 1.07006 1.21887 2.47459 1.96306 2.07102 2.76617 4.07263 1.26023 2.41363 3.27411 2.13488 2.74128 1.15457 2.98445 3.8842 1.80566 2.53726 4.45113 1.28946 1.33454 1.39152 2.63692 0.293422 1.14724 3.15641 2.0156 4.24582 4.46679 2.6578 1.00373 2.93351 2.83067 1.23767 0.999454 0.577831 3.60654 1.61926 2.24405 1.44815 0.462352 0.592519 3.82131 1.62338 0.576224 1.07524 3.52881 0.996322 2.60425 2.11441 2.19879 2.97623 3.38724 1.12683 2.23306 1.82733 2.68491 2.08185 1.27962 1.92477 2.24951 2.52182 5.6301 0.989162 3.52883 2.94754 1.9628 2.32643 2.26936 1.37925 3.1164 2.89264 0 0 0.244711 1.54536 2.29681 3.30117 0.596962 1.92545 3.34775 0.970405 3.22071 2.25907 2.17034 1.0912 1.66378 2.56899 1.38219 1.36976 1.72219 1.03898 2.49116 0.69391 0.460302 2.33333 3.99878 2.90573 4.23454 1.62861 2.24475 2.70933 3.44976 0 1.941 2.79438 0.722678 1.42198 1.83491 2.28547 3.01717 6.95832 1.24329 1.89873 1.0536 4.3093 3.85294 1.02162 2.21176 0.485196 1.80893 5.45467 1.00456 1.41126 2.62808 0.764197 4.48292 1.39009 5.0766 1.89962 1.94655 1.44354 2.30288 1.90389 2.49611 2.50873 3.10668 2.47424 3.60516 1.81642 2.45782 4.55232 3.03037 1.50585 2.38821 3.49425 3.54819 1.60359 4.37568 2.19055 3.86454 4.42827 1.77907 1.57204 1.81444 1.10172 2.24426 2.48265 1.55048 5.53549 3.48784 1.83227 4.06008 1.36126 1.39296 2.73858 1.74453 2.35309 2.66829 3.28519 1.82244 0.979425 3.27564 0.943543 1.8704 2.06166 1.86311 2.49375 2.82507 0 2.84343 2.04943 0.876048 2.1577 1.36979 1.81662 1.78943 6.5283 2.28454 2.00923 3.05926 1.16618 4.24807 6.6232 4.18265 1.50325 1.56547 5.00448 3.60885 2.91033 2.41125 4.1133 2.20384 1.63377 5.04061 3.63646 1.5469 1.36266 0.918208 2.26545 1.92814 1.87838 2.89992 2.71737 2.52722 1.73036 3.51528 1.63589 1.64761 4.00531 3.12761 3.08317 1.59265 2.34118 1.79362 2.00752 0.851292 1.85368 2.20094 1.29476 3.67528 0.205011 1.99513 1.42448 3.70815 1.5662 2.88523 3.68276 2.27109 1.09862 1.87452 1.53221 5.028 0.790561 1.77347 2.85113 1.53434 2.03542 4.30951 4.20273 2.63763 3.49498 0.81597 3.11209 0.885039 1.20399 2.84777 4.56018 3.49608 3.37513 1.10122 1.42976 1.82634 0 2.62104 1.52042 5.11335 2.11066 4.84045 2.00333 1.43582 0.949051 1.26423 3.64102 2.23977 6.63856 4.65375 1.48786 1.92741 2.34058 2.25359 3.11338 1.28013 4.46369 4.55797 1.43557 2.66758 1.77466 6.607 1.7355 1.47729 2.09575 5.25261 6.88182 4.22347 3.74551 3.60303 4.60882 2.71391 3.2366 1.10628 3.66581 6.13738 3.61613 0 1.56524 2.38991 3.83422 1.96829 3.3524 5.32095 1.06299 2.42513 1.90767 1.19127 4.58733 2.55711 2.21795 1.39694 2.67172 1.86138 2.27306 2.50772 2.33722 2.40774 2.8753 0.962848 2.22572 6.09119 1.27277 0.7574 1.24762 0.778914 1.27934 3.70998 4.82553 1.78125 3.93595 2.43231 6.28349 1.82002 1.91731 4.06957 4.65008 3.06959 4.39433 1.96531 1.29969 2.13767 1.18359 2.17398 5.27236 1.85552 1.14156 4.43028 2.22009 1.91926 2.72415 2.02191 2.464 1.08305 4.38566 1.09966 2.46569 0.700451 2.61084 1.67696 2.32585 1.726 1.7933 2.72309 2.07491 2.78183 2.55466 5.9901 4.63675 2.72412 2.03711 1.6324 1.56288 2.44641 1.29891 2.55792 3.5963 2.47235 4.44242 2.05385 2.95572 1.37378 1.9217 3.77204 2.77821 2.04356 1.42053 3.49014 3.53537 3.07686 2.01968 2.21103 1.49457 2.07459 2.48692 4.20364 1.61923 1.89441 2.34653 2.09852 1.70826 1.70055 4.86967 1.80041 4.15517 3.30597 2.64752 2.07267 1.91595 1.75718 0.629762 5.37877 3.68225 3.67853 1.16607 1.16939 3.9098 1.51078 2.05307 1.70951 3.46324 1.85774 3.25788 0 2.36514 1.73863 1.97218 2.81196 3.42111 2.99289 1.45791 1.75388 2.17021 1.40582 2.35547 5.36047 3.33938 5.42732 2.28495 1.56808 2.4253 1.74302 3.58277 3.53786 6.32751 2.86257 1.09064 3.13513 4.05711 0.958102 0.549331 2.95456 1.58887 0.785488 1.29027 5.52707 2.67759 5.83612 1.36269 3.29746 1.78145 3.67855 3.78073 3.59874 3.10248 1.61893 1.66526 1.75414 2.21175 2.76845 1.37199 3.01958 1.73231 2.5538 3.15874 3.15804 1.73828 1.29166 3.42803 3.7063 2.15256 2.57986 1.71909 0.851084 2.00782 3.05068 3.57707 2.26933 1.14044 1.38934 1.97505 1.04721 0.954061 1.0213 4.47261 3.28183 3.30595 5.22354 1.39873 1.00387 2.15841 1.39203 0 2.31557 1.31991 2.2585 1.56625 2.63452 1.42851 1.8595 2.68904 2.53903 2.56052 3.0838 2.11519 3.01577 1.44666 1.53503 1.06228 1.29669 1.26263 5.80604 1.46527 2.426 5.58015 1.76085 3.15448 1.8099 1.4807 2.97543 1.73389 2.66607 3.6214 3.62679 2.37523 3.35482 1.39137 1.34657 3.61143 2.75954 3.13818 0.69446 2.71203 2.1135 2.04912 2.26295 3.21247 2.98567 1.70896 2.52726 2.43618 2.43833 2.62124 2.48559 2.21429 2.57385 2.86224 2.7638 2.19685 2.71494 2.88806 1.45888 1.36787 5.40651 0.742366 2.57336 1.99368 2.71268 3.55448 1.82373 1.34172 3.59648 3.95991 4.04367 3.38867 2.87037 1.33356 5.58503 2.53114 0.604501 2.56935 2.761 1.30061 1.8449 4.43166 1.82932 4.03118 3.89872 2.77317 4.42826 0.80557 0.877686 1.81467 3.26104 2.14299 2.39631 2.39531 1.93013 3.66003 2.25387 1.77202 1.79417 1.63631 2.65766 1.98407 4.06578 3.37447 2.53518 2.98281 1.67322 2.00831 1.88955 0.911453 2.61618 1.62662 3.81895 1.53293 2.18449 4.61248 0.889292 5.0872 3.3123 1.72222 2.49617 1.6298 2.45642 2.45363 3.32234 2.93197 4.35597 2.70161 3.3658 1.2428 2.80082 1.79411 1.83578 1.58575 4.99813 2.19218 2.23719 3.19175 4.44711 0.568639 2.58671 4.79105 2.08604 3.12064 4.36821 2.6899 1.97893 3.67366 4.17557 1.63681 1.88553 4.61699 0.771308 2.17076 2.9663 3.65751 1.53892 4.49595 1.33367 5.82609 3.54625 3.16754 2.723 1.81744 4.00776 1.51936 2.52913 1.04315 1.8187 3.02466 1.66979 1.72638 3.3275 2.08103 2.22381 1.31707 2.63288 1.07012 2.55421 1.24976 2.79708 2.35032 1.34 3.09498 2.03032 3.83945 1.73968 2.0296 3.05564 4.04028 2.5883 2.94842 3.72049 1.09895 0.868675 2.655 3.20391 1.20058 2.74994 2.14383 2.45187 2.13297 1.86986 2.81287 3.17059 0.360393 1.8218 3.28356 2.53356 2.8969 3.54081 3.6209 1.76294 2.7542 1.10969 2.55504 1.49582 0.87779 2.5491 4.44905 0 3.16987 2.75094 2.18471 2.1665 0.827302 4.15409 1.56119 2.95293 3.5046 2.79825 3.90361 1.26853 5.03027 1.15529 1.96505 4.82097 1.54494 4.20059 2.6974 2.88223 2.65648 6.95605 2.29174 3.47818 5.22882 5.88212 3.71126 1.77931 0.797421 2.86389 1.09284 2.64594 3.86136 2.68125 2.42352 1.60708 4.06127 1.53949 3.4537 1.62626 2.42276 1.20113 5.74781 3.20101 1.514 3.99022 5.13212 3.47581 3.4438 3.15795 4.21403 3.02415 1.00409 1.12214 1.00694 3.25829 1.95091 3.39119 1.33747 1.20791 1.33659 2.3175 3.63697 3.42223 3.57981 0.645879 3.70206 1.38248 1.97329 4.69753 0.936959 0.854487 0.958442 2.90026 1.97773 2.04175 2.43611 2.47256 2.85338 3.88063 0.961785 3.60021 2.45876 1.69327 2.95645 2.51268 6.08654 2.5003 1.21116 4.07068 2.73934 1.70264 3.60556 2.47883 2.07721 3.8231 2.21644 3.62193 2.06154 3.41222 1.33215 2.77372 3.83442 2.50977 1.87073 1.33704 4.45826 2.29501 2.18074 3.11229 1.54018 3.91674 3.51763 0 3.23899 1.65555 4.8272 3.46378 2.61302 3.67961 1.94065 3.69888 2.1664 2.12926 2.24225 2.32152 2.23982 2.26837 5.62438 2.68072 2.88068 1.10674 2.07196 3.17565 3.14687 3.87839 0.862628 2.76445 2.63044 2.28111 2.58234 1.28998 5.03512 1.23356 1.60077 3.34557 4.41247 2.08314 1.86842 1.21094 4.86094 0.863223 0.843291 1.20651 2.23918 1.45993 1.30415 2.15797 1.1299 2.22311 3.03826 3.00655 1.0206 1.8969 2.88635 2.2336 1.7254 ]
@@@ Frame-accuracy per-class: [ 77.1625 49.1803 23.5294 41.5094 57.1429 30.7692 57.1429 74.2857 36.8794 50.7937 35.5556 38.3562 78.2609 32.9114 0 28.0374 48.2759 17.4274 31.1111 87.8049 60.8696 48.1203 31.1688 59.1549 62.8571 48.9796 53.3333 0 50.5747 62.8571 5.78035 14.9254 56.4103 15.3846 90.9091 91.3907 34.7418 57.1429 0 73.0184 50.3259 22.2222 40.9449 68.6347 26.6667 29.5082 24.8447 7.1066 47.191 71.2644 21.0526 20.7407 36.0902 14.5455 67.4699 34.9515 44.6512 86.2385 74.2557 51.8519 20.6186 40.8163 87.1961 54.382 0 33.8028 42.4242 29.8507 65.1911 58.0645 56.8807 44.4444 35.8423 60.1227 62.069 44.4444 28.5714 90.1408 63.1579 79.2453 40 36.0902 0 82.7586 51.6854 31.3725 0 34.3434 45.7399 26.087 13.7566 83.7209 42.7586 43.4783 37.594 7.27273 86.1538 38.806 40.7643 77.6471 12.9032 34.7826 0 52.3985 85.3333 22.2222 60.3175 41.8605 26.6667 60.4651 35.5556 0 23.5294 66.1871 42.5532 0 40.5797 28.5714 15.3846 37.3333 43.1373 14.4928 37.8378 25.641 84.2105 45.977 21.5054 22.2222 88.8889 64.1509 54.2373 43.1373 40 32.1839 26.8657 75.2 56 84.264 43.0769 43.1373 8.88889 67.5159 43.4783 41.6 0 88.8889 56.4972 21.3333 35.1648 59.0164 71.4894 30.9859 46.281 41.5584 53.3333 88.8031 54.5455 51.0638 60.4651 25.9542 54.2373 61.2245 19.0476 0 66.6667 20.8955 31.8841 48.4848 76.1905 2.24719 69.7674 35.2941 57.7778 27.451 0 73.6842 65.5738 43.4783 28.2353 36.6197 66.6667 48 0 70.5882 64.6154 40 52.6316 34.1463 58.4615 32.9897 73.8462 37.6471 47.7876 52.0548 64.7887 67.4699 21.8182 12.1212 0 91.5254 28.169 22.2222 72 26.6667 10.5263 63.7363 21.8182 74.8466 55.814 6.06061 46.1538 37.2414 67.7966 0 21.5054 69.5035 26.2774 61.3333 26.4151 62.6866 29.703 48 49.2308 52.6316 18.1818 30.1887 25.5319 0 82.7586 31.1284 36.1905 52.4272 38.6555 34.1463 0 23.5294 57.1429 0 11.4286 64.6154 0 30.303 0 70.8861 19.8347 0 54.5455 0 30.7692 9.7561 0 26.6667 20.9524 62.2222 37.3333 64.5161 67.6923 64 30.3797 87.8307 62.069 66.6667 35.2941 45.7143 54.6763 92.9577 11.7647 52.1739 96.2963 64.8649 29.0598 64.1509 20.4082 23.431 42.4242 0 94.7368 0 59.2593 53.5211 70.2703 51.8519 57.1429 22.7545 57.1429 39.0244 82.9268 70.7692 0 56.4103 44.7761 41.1483 41.2371 90.9091 2.51572 33.6842 53.6585 20.6897 10.9091 4.0404 44.2478 26.6667 29.2683 28.9855 87.7193 80 0 28.5714 32.5581 4.44444 58.0645 32.7273 45.5696 92.3077 0 26.087 44.4444 54.902 48.4211 0 0 48.2759 0 89.2562 0 20.6897 30.1887 6.89655 47.0588 38.0952 60.9929 44.4444 32.2581 50.8475 86.9565 47.9401 43.4783 47.8873 35.5556 36.8932 55.814 62.6087 68.9655 59.3607 25.8065 21.9178 33.8983 18.1818 79.0698 29.2683 32.4324 35.8974 68.9956 75.6757 46.0432 50.7042 37.2093 32.5581 20.155 44.9438 68.3544 13.7931 38.7097 37.2093 72 15.873 64.5161 65.2482 40 31.3725 25.7426 37.1134 73.8916 50.6667 83.0769 80 72.4638 72.8972 32.5203 52.1008 47.7612 24.4898 80 78.7879 59.1549 63.1579 60.3774 27.5862 41.7582 8 63.4146 30.303 13.6986 43.0108 0 66.6667 28.0702 0 32 44.4444 0 61.0169 66.6667 63.5514 7.40741 92.6829 63.1579 23.1293 33.9181 7.00389 9.21659 32.5581 80 24.7191 16.3934 61.5385 64 86.0215 6.45161 33.8462 35.3591 44.4444 87.8049 89.2308 22.8571 55.814 80 65.9341 8.69565 74.4186 28.3063 40.404 31.3725 45.9016 22.2222 71.1864 41.958 59.2593 31.3043 45.3608 55.8376 51.6129 36.3636 36.1446 0 77.686 0 22.2222 54.5455 22.6804 49.505 54.5455 23.622 37.7622 0 0 94.1176 52.6316 0 30.303 89.4118 44.9438 6.06061 82.5175 14.5455 38.7097 50.5051 80 62.2222 34.7826 59.0164 56.2963 43.3735 69.0265 32.2581 77.193 89.7959 45.0704 26.6667 0 0 49.2754 26.6667 11.7647 10.3896 0 42.1053 17.5439 85.2174 49.505 56 29.6296 10.1266 3.50877 64.1975 49.9665 61.9718 7.40741 0 46.1538 27.027 98.1818 24 0 78.0952 52.8926 46.5116 78.7879 0 65.6716 2.0202 45.8101 15.3846 46.7532 44.7059 64.8649 31.068 37.9747 15.0943 0 15.3846 66.6667 34.0426 0 21.6216 50.4854 34.5178 22.5352 16 76.1905 14.4928 26.087 10.6195 10.9689 53.3333 60.7595 44.4444 54.0541 37.2093 25.8065 44.898 17.7778 12.9032 58.8235 0 60.4651 63.5514 28.5714 65.3061 7.84314 19.3548 22.2222 44.4444 77.193 20.6897 63.1579 35.2941 28.5714 23.5294 33.8983 0 0 47.0588 54.0541 81.5534 41.9048 68.0412 55.3191 28.5714 0 6.06061 57.1429 0 53.7634 18.1818 0 21.3333 60.6897 0 7.79221 11.7647 25.8065 18.1818 0 34.4828 44.0367 32.381 21.5385 36.8932 66.6667 75.8621 37.2093 43.7333 44.4444 32.8358 30.303 38.7097 54.0541 5.12821 47.619 43.0769 7.01754 16 16.9492 72.2892 24.7619 38.0952 30.7692 72.2513 32.4324 49.4624 65.4206 22.8571 94.1176 36.3636 64.8649 12.6984 70.9677 20.6897 0 40 70.5882 51.4286 26.6667 33.1551 70.1754 41.3793 27.907 66.6667 25.8065 23.5294 18.5567 32.0988 23.7288 83.0769 32.2581 95.2381 52.8302 28.5714 14.0541 22.2222 18.3486 64.7423 0 42.6036 0 40 59.4595 29.1391 40.7273 0 31.2757 41.0256 69.5652 63.4146 12.1212 39.6396 2.33918 0 51.4286 11.9403 35.514 47.0588 35.5828 53.8922 0 0 65.7534 23.4234 24.8062 0 51.1278 60.355 35.7895 0 0 18.5792 11.4943 15.3846 0 29.7872 26.6667 74.2857 20.5128 0 12.2449 0 65.5462 46.3277 11.3208 38.7097 24.3902 0.896861 66.6667 53.4653 26.6667 58.4615 4.44444 0 40 64.5161 24.5614 49.3506 48.8889 29.0909 35.0877 39.1753 15.2381 69.8795 17.5439 0 62.8821 74.8815 74.6667 80.8889 75.8621 0 0 0 11.4286 32.4607 0 52.7473 12.9032 0 0 36.7347 7.63359 28.5714 47.2727 47.4576 63.9456 45.6693 12.6316 34.2857 75.3623 10.8108 33.6449 51.4286 56 57.1429 24.3902 30.7692 6.89655 63.0137 45.8599 73.1707 0 55.1724 34.0426 56.8421 30.7692 15.3846 48.8889 0 17.3913 5.58659 0 0 21.6216 53.6585 62.116 27.451 58.8235 19.6078 4.49438 33.8983 24.5614 57.7778 18.8679 57.971 40.8163 6.80272 23.1884 23.3918 51.7647 18.6667 5.6338 26.4151 32.0988 35.443 66.6667 36.9231 29.7872 10.8108 56.4593 35.1145 42.1053 41.7582 61.5385 41.8605 0 30.9278 16.4706 4.65116 24.6914 42.1053 35.2941 43.6364 89.7959 4.25532 0 0 72.9223 65.272 0 53.0387 25.4545 59.5745 21.2766 38.961 6.18557 0 38.5965 52.6316 47.5524 30.7692 29.6296 20.4082 40 43.1373 41.0256 48.4848 59.5745 0 7.72201 5.94059 37.6812 65.1163 31.6547 43.0769 0 15.0943 0 13.7931 69.1824 0 0 67.6056 83.8323 12.2449 51.1628 78.0488 73.6842 6.22568 25.8824 24.0602 61.5385 0 47.0588 7.01754 22.6415 14.876 7.54717 41.0959 59.0164 50.5837 33.0579 35.2941 58.0645 36.7347 40.3361 29.4737 0 25.641 56.6929 72.9412 22.2222 0 3.38983 19.6721 48.4848 76.3359 40 0 29.2683 40 69.9301 59.7938 46.1538 68.5714 73.9496 77.193 8.16327 0 34.1463 0 64.1509 69.3878 32.2581 59.1549 0 51.4286 70.4225 29.6296 57.6271 6.89655 56.8421 42.4242 0 37.037 0 22.8571 28.5714 30.7692 59.7403 38.7097 67.2897 71.777 75.3623 5.83942 64 25.5319 0 46.3768 20.339 53.3333 38.7097 7.56757 68.8525 35.0515 31.746 0 22.9508 18.1818 51.8519 53.0612 24.7191 30.2158 22.9885 92.3077 35.1145 51.6129 30.5085 0 35.0877 31.9703 48.9796 14.6341 52.1739 37.5758 23.1214 40.678 44.4444 27.907 48 9.52381 32.6531 16 17.1779 58.7156 48 3.61757 76.9231 38.5965 32.9114 46.1538 31.746 38.2979 65.7534 27.4809 17.3913 25.3165 14.0969 26.2295 52.1739 0 15.9363 90.1099 24.7619 31.8841 66.2857 29.2683 13.5593 42.4242 12.3077 16.4706 24.6154 7.54717 76.9231 73.4177 70.9677 31.0502 33.6449 32.4324 35.2941 40 29.8507 47.4576 57.1429 47.619 61.5385 27.451 35.1648 10.2564 8.69565 53.0612 23.8806 58.5366 26.4151 42.1053 71.1864 44.1315 62.2951 2.98507 70.2703 30.9278 14.1593 76.3006 10.8108 8.51064 56 42.5532 34.4828 0 27.5862 16.4384 26.2626 10.1083 29.7521 20.4196 66.6667 22.3938 46.6019 53.1646 50.8475 0 44.8598 45.1613 13.7931 7.40741 87.6404 28.5714 12.0482 53.012 35.2941 5.40541 21.5385 42.4242 29.2683 9.30233 40 58.8235 6.21762 72.7273 51.0638 49.2013 13.1868 46.9945 0 61.5385 0 28.866 11.7647 35.1648 50.8475 0 53.3333 25.5319 79.3651 35.2941 0 60.9572 38.0952 20.6897 40.678 47.0588 73.4177 35.6589 68.3544 26.087 71.6981 24.5614 43.038 53.886 14.8148 37.3832 0 60.8696 31.5789 17.3913 13.9535 20.7407 10.5263 0 67.3267 76.9231 9.52381 26.087 53.3333 21.2766 32.2581 14.8148 59.0164 45.9016 44.1926 18.6667 97.0414 52.1739 8.83534 27.907 14.7651 15.3846 35.5828 57.4713 25.5319 58.8235 35.0365 74.2857 86.2275 25.4545 14.6341 0 26.8657 19.469 48.2759 42.5532 81.9672 0 50.566 31.7181 0 36.3636 0 58.0645 0 36.3636 38.961 0 58.4615 14.1844 28.169 31.4607 24.6575 1.21212 16 20.5128 7.84314 15.9292 0 53.0612 75.3799 25.7703 53.0612 32.9412 0 25.641 26.087 55.4217 16.2963 67.5556 17.3913 58.1818 38.4 70.8861 0 15.0943 60.6061 15.3846 0 22.7848 23.5294 25.8065 9.91736 34.1463 78.3673 67.8899 61.9718 40.8163 34.9515 28.0702 57.1429 37.037 60.3878 53.7705 20.2532 5.04202 20.6897 94.1176 25.9109 63.8298 50.2831 6.89655 81.6901 73.9726 70.9753 13.3333 44.7761 44.4444 36.1446 24.6154 14.433 38.5542 63.7771 24.2424 16.2162 57.9186 17.6991 38.3562 5.33333 39.0977 77.6119 25.2632 9.30233 32.2581 6.77966 28.4024 30.7692 8.24742 37.8947 0 44.4444 13.7931 62.2222 14.0845 13.278 38.5787 43.9024 62.1849 6.92168 34.2857 25.8065 13.3333 58.0645 3.36134 12.1212 0 7.27273 57.1429 7.40741 4.21053 33.0709 5.7554 36.3636 8.75912 27.6923 35.443 45.721 58.0645 45.045 37.2881 3.50877 33.6842 41.3793 68.2353 30.5882 13.7931 40 3.50877 75.1131 38.2979 36.3636 36.3636 8 49.3151 0 80.5195 74.4186 15.6522 0 18.6667 54.321 54.902 0 79.0698 68.8172 55.0459 27.1186 56.1798 58.5859 24.2424 73.1183 37.037 4.12371 0 77.2947 40 19.7183 32 55.0725 ]

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:347) Done 295 files, 0 with no tgt_mats, 0 with other errors. [CROSS-VALIDATION, 0.0211609 min, fps62388.8]
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:353) AvgLoss: 2.05063 (Xent), [AvgXent: 2.05063, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 45.5613% <<

WARNING (nnet-train-multistream-perutt[5.5.1074~1-71f3]:Close():kaldi-io.cc:515) Pipe ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl "ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- | had nonzero return status 36096
