speech-HP-Z2-Tower-G9
nnet-train-multistream-perutt --cross-validate=true --randomize=false --verbose=0 --num-streams=10 --max-frames=15000 --feature-transform=exp_FG/blstm4i/final.feature_transform 'ark:copy-feats scp:exp_FG/blstm4i/cv.scp ark:- | apply-cmvn --norm-means=true --norm-vars=true --utt2spk=ark:data-fbank/train_cv10/utt2spk scp:data-fbank/train_cv10/cmvn.scp ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |' 'ark:ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl "ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp_FG/blstm4i/nnet/nnet_iter07 
WARNING (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuId():cu-device.cc:243) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:438) Selecting from 1 GPUs
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:453) cudaSetDevice(0): NVIDIA RTX A2000 12GB	free:11620M, used:410M, total:12031M, free/total:0.96589
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:501) Device: 0, mem_ratio: 0.96589
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuId():cu-device.cc:382) Trying to select device: 0
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:SelectGpuIdAuto():cu-device.cc:511) Success selecting device 0 free mem ratio: 0.96589
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:FinalizeActiveGpu():cu-device.cc:338) The active GPU is [0]: NVIDIA RTX A2000 12GB	free:11106M, used:924M, total:12031M, free/total:0.923168 version 8.6
copy-feats scp:exp_FG/blstm4i/cv.scp ark:- 
apply-cmvn --norm-means=true --norm-vars=true --utt2spk=ark:data-fbank/train_cv10/utt2spk scp:data-fbank/train_cv10/cmvn.scp ark:- ark:- 
add-deltas --delta-order=2 ark:- ark:- 
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:144) CROSS-VALIDATION STARTED
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:Read():nnet/nnet-matrix-buffer.h:191) Read() started... Buffer size in MB: 0, max 3072, having 0 utterances.
ali-to-post ark:- ark:- 
ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl 'ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |' ark:- 
LOG (copy-feats[5.5.1074~1-71f3]:main():copy-feats.cc:143) Copied 296 feature matrices.
LOG (apply-cmvn[5.5.1074~1-71f3]:main():apply-cmvn.cc:159) Applied cepstral mean and variance normalization to 296 utterances, errors on 0
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:303) ### After 0 frames,
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:304) num-components 4
input-dim 78
output-dim 1280
number-of-parameters 2.04864 millions
component 1 : <BlstmProjected>, input-dim 78, output-dim 640, cell-dim 2x320 ( learn_rate_coef_ 1, bias_learn_rate_coef_ 1, cell_clip_ 50, diff_clip_ 1, grad_clip_ 250 )
  Forward Direction weights:
  f_w_gifo_x_   ( min -0.686081, max 0.746735, mean 0.00389883, stddev 0.088032, skewness 0.0112436, kurtosis 0.927634 ) 
  f_w_gifo_r_   ( min -0.424222, max 0.413743, mean -0.000587032, stddev 0.0787126, skewness -0.00333338, kurtosis 0.0235455 ) 
  f_bias_   ( min -0.351889, max 1.38379, mean 0.211202, stddev 0.464323, skewness 1.06073, kurtosis -0.650783 ) 
  f_peephole_i_c_   ( min -0.621049, max 0.504573, mean -0.00362917, stddev 0.132112, skewness -0.062059, kurtosis 2.11466 ) 
  f_peephole_f_c_   ( min -0.706738, max 0.759955, mean 0.00455142, stddev 0.173853, skewness 0.18798, kurtosis 3.47898 ) 
  f_peephole_o_c_   ( min -0.675701, max 0.496666, mean -0.0102628, stddev 0.19194, skewness 0.0631598, kurtosis -0.0257423 ) 
  f_w_r_m_   ( min -0.510858, max 0.502346, mean 0.000601689, stddev 0.104422, skewness 0.00182213, kurtosis 0.0251966 ) 
  Backward Direction weights:
  b_w_gifo_x_   ( min -1.65715, max 1.10765, mean 0.00609001, stddev 0.0952547, skewness -0.171456, kurtosis 4.91685 ) 
  b_w_gifo_r_   ( min -0.348904, max 0.367284, mean -0.000200308, stddev 0.0722196, skewness 0.000304645, kurtosis -0.236067 ) 
  b_bias_   ( min -0.389512, max 1.22297, mean 0.205265, stddev 0.454035, skewness 1.0348, kurtosis -0.69304 ) 
  b_peephole_i_c_   ( min -0.423105, max 0.313897, mean 0.00699103, stddev 0.101187, skewness -0.136644, kurtosis 1.34592 ) 
  b_peephole_f_c_   ( min -0.563952, max 0.746451, mean 0.0167046, stddev 0.177378, skewness 0.578724, kurtosis 3.06632 ) 
  b_peephole_o_c_   ( min -0.57515, max 0.538246, mean -0.0158073, stddev 0.197649, skewness -0.164656, kurtosis 0.350606 ) 
  b_w_r_m_   ( min -0.409727, max 0.396105, mean -0.000354284, stddev 0.0940523, skewness -0.00200197, kurtosis -0.0343945 ) 
component 2 : <Tanh>, input-dim 640, output-dim 640, 
component 3 : <AffineTransform>, input-dim 640, output-dim 1280, 
  linearity ( min -0.96999, max 0.756577, mean -0.000155915, stddev 0.108394, skewness 0.00561884, kurtosis 0.0595853 ) , lr-coef 1, max-norm 0
  bias ( min -0.0883743, max 2.50188, mean -1.81608e-09, stddev 0.0827467, skewness 22.8174, kurtosis 659.944 ) , lr-coef 1
component 4 : <Softmax>, input-dim 1280, output-dim 1280, 

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:305) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -11.004, max 12.2048, mean 0.00682255, stddev 0.969149, skewness 0.287893, kurtosis 3.83541 ) 
[1] output of <BlstmProjected> ( min -4.50773, max 3.91491, mean -0.00138628, stddev 0.760582, skewness -0.0026349, kurtosis 0.928304 ) 
[2] output of <Tanh> ( min -0.999757, max 0.999205, mean -0.000876252, stddev 0.516178, skewness 0.000111642, kurtosis -0.846251 ) 
[3] output of <AffineTransform> ( min -12.3226, max 20.1894, mean 0.00851594, stddev 2.43632, skewness 0.690105, kurtosis 2.22141 ) 
[4] output of <Softmax> ( min 3.41795e-13, max 0.998848, mean 0.000780053, stddev 0.0175136, skewness 38.6832, kurtosis 1699.75 ) 
### END FORWARD

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:334) ### After 79212 frames,
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:335) num-components 4
input-dim 78
output-dim 1280
number-of-parameters 2.04864 millions
component 1 : <BlstmProjected>, input-dim 78, output-dim 640, cell-dim 2x320 ( learn_rate_coef_ 1, bias_learn_rate_coef_ 1, cell_clip_ 50, diff_clip_ 1, grad_clip_ 250 )
  Forward Direction weights:
  f_w_gifo_x_   ( min -0.686081, max 0.746735, mean 0.00389883, stddev 0.088032, skewness 0.0112436, kurtosis 0.927634 ) 
  f_w_gifo_r_   ( min -0.424222, max 0.413743, mean -0.000587032, stddev 0.0787126, skewness -0.00333338, kurtosis 0.0235455 ) 
  f_bias_   ( min -0.351889, max 1.38379, mean 0.211202, stddev 0.464323, skewness 1.06073, kurtosis -0.650783 ) 
  f_peephole_i_c_   ( min -0.621049, max 0.504573, mean -0.00362917, stddev 0.132112, skewness -0.062059, kurtosis 2.11466 ) 
  f_peephole_f_c_   ( min -0.706738, max 0.759955, mean 0.00455142, stddev 0.173853, skewness 0.18798, kurtosis 3.47898 ) 
  f_peephole_o_c_   ( min -0.675701, max 0.496666, mean -0.0102628, stddev 0.19194, skewness 0.0631598, kurtosis -0.0257423 ) 
  f_w_r_m_   ( min -0.510858, max 0.502346, mean 0.000601689, stddev 0.104422, skewness 0.00182213, kurtosis 0.0251966 ) 
  Backward Direction weights:
  b_w_gifo_x_   ( min -1.65715, max 1.10765, mean 0.00609001, stddev 0.0952547, skewness -0.171456, kurtosis 4.91685 ) 
  b_w_gifo_r_   ( min -0.348904, max 0.367284, mean -0.000200308, stddev 0.0722196, skewness 0.000304645, kurtosis -0.236067 ) 
  b_bias_   ( min -0.389512, max 1.22297, mean 0.205265, stddev 0.454035, skewness 1.0348, kurtosis -0.69304 ) 
  b_peephole_i_c_   ( min -0.423105, max 0.313897, mean 0.00699103, stddev 0.101187, skewness -0.136644, kurtosis 1.34592 ) 
  b_peephole_f_c_   ( min -0.563952, max 0.746451, mean 0.0167046, stddev 0.177378, skewness 0.578724, kurtosis 3.06632 ) 
  b_peephole_o_c_   ( min -0.57515, max 0.538246, mean -0.0158073, stddev 0.197649, skewness -0.164656, kurtosis 0.350606 ) 
  b_w_r_m_   ( min -0.409727, max 0.396105, mean -0.000354284, stddev 0.0940523, skewness -0.00200197, kurtosis -0.0343945 ) 
component 2 : <Tanh>, input-dim 640, output-dim 640, 
component 3 : <AffineTransform>, input-dim 640, output-dim 1280, 
  linearity ( min -0.96999, max 0.756577, mean -0.000155915, stddev 0.108394, skewness 0.00561884, kurtosis 0.0595853 ) , lr-coef 1, max-norm 0
  bias ( min -0.0883743, max 2.50188, mean -1.81608e-09, stddev 0.0827467, skewness 22.8174, kurtosis 659.944 ) , lr-coef 1
component 4 : <Softmax>, input-dim 1280, output-dim 1280, 

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:336) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.66434, max 7.26584, mean -0.0147177, stddev 0.961893, skewness 0.577064, kurtosis 2.62679 ) 
[1] output of <BlstmProjected> ( min -3.90458, max 3.84724, mean -0.000485969, stddev 0.710877, skewness -0.0341281, kurtosis 1.67093 ) 
[2] output of <Tanh> ( min -0.999188, max 0.99909, mean 0.000704225, stddev 0.479943, skewness -0.0107385, kurtosis -0.52663 ) 
[3] output of <AffineTransform> ( min -12.8858, max 20.6317, mean 0.0160343, stddev 2.30631, skewness 0.856996, kurtosis 3.56434 ) 
[4] output of <Softmax> ( min 1.24516e-12, max 0.996607, mean 0.000780864, stddev 0.0187234, skewness 35.8487, kurtosis 1462.54 ) 
### END FORWARD

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:346) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 1670 30 8 79 45 6 24 17 70 220 22 36 34 39 10 53 43 120 22 20 34 66 38 35 87 73 52 35 43 17 86 33 19 32 16 75 106 10 5 1873 21251 22 63 135 22 30 80 98 44 43 9 67 66 27 41 51 107 54 285 40 48 24 308 222 21 35 16 33 248 15 54 49 139 81 14 4 45 35 47 26 17 66 4 14 44 25 18 49 111 11 94 64 72 34 66 27 32 33 78 42 15 34 9 135 37 103 31 64 37 21 67 0 93 69 23 2 34 10 32 37 25 34 18 19 28 43 46 13 4 26 88 25 22 43 33 62 12 98 32 25 22 78 11 62 24 13 88 37 45 30 117 35 60 38 37 129 16 23 64 982 29 24 10 20 31 33 34 16 52 44 64 25 22 25 3 9 30 11 42 35 13 12 11 8 32 32 9 20 32 48 32 42 56 36 35 41 27 16 5 29 35 31 12 7 9 45 27 81 21 16 19 72 29 0 46 70 68 37 26 33 50 37 32 9 5 26 23 15 14 128 52 51 59 20 20 8 73 5 17 32 22 16 4 39 60 11 16 7 19 20 8 7 52 22 37 15 32 12 39 94 72 13 59 17 69 35 25 11 13 18 58 26 24 119 16 14 9 5 13 35 18 40 17 83 10 20 20 32 21 19 33 104 48 60 79 47 20 14 27 49 56 7 20 34 199 37 4 3 21 22 15 27 39 6 10 11 22 25 47 21 6 14 6 60 3 43 26 14 8 10 70 4 15 29 11 133 11 35 22 51 21 57 14 109 15 36 29 5 21 20 18 19 114 55 69 35 21 21 64 44 39 43 15 21 37 31 46 70 32 25 50 48 101 37 32 62 34 53 184 59 33 24 47 16 35 9 79 14 45 12 20 16 36 46 8 52 28 13 12 31 17 29 40 53 13 20 9 73 85 128 108 21 7 44 30 32 12 46 15 32 90 31 20 32 52 21 237 45 11 21 215 49 25 30 31 29 71 13 57 48 98 46 27 41 19 60 21 4 38 48 50 5 63 71 0 0 25 47 11 16 42 44 49 71 27 15 49 22 22 11 30 67 41 56 15 28 24 35 7 14 15 34 7 8 38 0 9 28 57 50 12 13 39 28 40 746 35 13 19 19 18 27 12 16 52 60 21 82 1 33 49 89 6 38 42 18 51 39 26 11 19 7 23 28 18 51 98 35 37 10 34 11 56 273 7 39 31 18 21 15 24 22 15 25 6 21 53 59 24 25 15 4 49 28 14 9 8 3 8 29 34 0 8 18 51 52 48 23 3 60 16 24 35 46 16 52 37 72 3 38 59 15 5 40 14 54 52 32 51 4 14 21 187 40 33 16 15 18 19 52 32 28 37 29 41 52 10 6 95 18 46 53 17 8 5 18 31 15 14 27 7 8 17 7 93 28 14 64 22 15 8 48 40 29 32 15 10 26 38 92 13 54 242 3 84 0 22 55 226 137 6 121 19 57 20 16 55 85 4 17 33 53 42 81 83 26 30 36 55 64 9 66 84 47 14 13 91 43 19 13 23 37 17 19 27 24 0 59 88 26 15 20 111 16 50 7 32 22 5 17 15 28 38 22 27 28 48 52 41 28 16 114 105 37 112 43 4 69 17 87 95 11 45 15 22 24 24 65 3 27 29 73 63 47 17 34 18 53 17 37 17 20 6 14 36 78 20 8 14 23 47 6 6 22 3 11 89 3 5 18 20 146 25 8 25 44 29 28 22 26 34 24 73 34 85 42 37 35 79 40 39 34 32 23 18 104 65 9 45 19 21 17 48 42 21 40 28 25 27 73 23 34 2 186 119 39 90 27 23 23 38 48 0 28 66 71 45 13 24 7 25 19 16 23 24 129 50 34 21 69 32 14 26 16 14 79 10 15 35 83 24 21 61 28 128 42 66 19 12 25 28 26 60 26 36 30 128 60 8 15 24 59 47 2 19 63 42 22 4 29 30 49 65 12 8 20 32 71 48 32 17 59 28 24 21 20 22 26 24 15 35 0 17 35 13 29 14 47 49 7 13 6 17 31 19 38 15 53 143 34 68 37 23 6 34 29 7 46 92 30 48 31 3 30 16 40 24 44 69 43 19 65 170 29 5 28 134 73 20 11 82 86 29 13 21 12 10 24 12 81 163 12 193 6 28 39 45 31 23 36 65 11 39 113 30 11 28 125 45 52 34 87 20 29 16 97 42 97 26 45 39 15 109 53 18 59 52 33 29 52 31 45 25 45 136 11 24 33 61 26 28 29 106 30 33 18 48 56 86 92 23 37 23 14 2 14 36 346 138 60 357 25 129 51 39 29 11 53 15 14 13 44 38 41 41 8 18 32 16 20 21 17 8 96 16 23 156 45 91 21 6 43 48 25 45 29 8 22 23 31 42 3 198 10 14 29 25 39 64 39 11 26 28 39 96 13 53 5 34 9 11 21 67 28 24 50 19 10 11 22 23 15 13 30 30 176 37 84 80 124 21 74 32 81 43 23 25 68 52 83 27 20 0 33 56 14 23 30 22 132 113 9 71 18 15 16 5 38 61 32 70 35 44 36 82 12 19 25 56 12 24 164 178 24 42 24 19 11 41 67 112 11 27 62 39 5 26 82 58 18 39 25 15 60 20 122 54 35 24 51 28 24 13 180 152 39 59 14 42 123 70 441 14 35 36 425 22 33 13 41 32 48 41 161 16 18 110 56 36 262 66 33 47 21 15 29 84 58 48 47 2 22 14 22 35 120 98 20 59 274 17 15 22 15 59 16 0 27 31 40 47 63 69 16 68 32 39 426 46 55 29 28 47 14 42 42 14 17 28 110 23 16 27 12 36 25 38 21 57 45 37 40 25 7 21 46 54 29 44 49 16 46 13 48 16 103 37 35 12 34 ]
@@@ Loss per-class: [ 0.640487 1.13927 1.44823 1.61105 1.28221 2.75394 1.67374 0.766659 3.09307 0.905572 1.65979 2.82433 0.607217 2.79634 0.901326 3.66392 1.61411 2.53988 4.36402 0.814228 1.70561 1.67795 5.17884 1.90307 0.838896 1.7542 1.15972 3.85453 1.63275 1.20926 4.43559 5.3301 1.6904 4.82948 0.231286 0.712492 2.3156 1.29768 2.99843 0.940808 1.43297 2.5082 4.18612 1.78184 2.93549 2.52691 1.79451 7.28922 1.34958 1.27164 2.30453 2.61244 2.33355 1.75718 1.27902 1.68075 1.33782 0.652579 1.32568 1.66273 3.22733 2.17365 0.546102 1.80477 3.32496 1.05771 2.25497 1.8788 0.569536 1.8691 1.609 1.66166 1.96857 1.86995 0.838888 1.2333 2.63827 0.257543 2.17744 1.59495 1.98435 2.13169 3.17734 1.02366 1.48491 1.81294 1.96399 3.2591 1.58636 1.7399 2.17224 0.456503 1.30165 3.24633 4.05106 3.2726 0.998196 1.75883 1.18961 1.23398 4.8335 2.61168 1.57262 1.40857 1.18493 3.67933 2.51832 1.35613 2.54773 0.910351 2.55292 0 3.11791 1.8354 1.63472 1.88685 1.74114 2.67655 1.97164 2.40973 1.91841 2.92366 3.06527 1.96047 0.713577 2.10275 3.3303 3.42621 0.425396 1.2149 1.45385 1.21807 1.61503 2.53839 2.57761 1.22818 2.34175 0.533669 1.74734 2.49029 3.2042 1.03021 1.13254 2.13924 3.08639 0.0735466 1.20489 2.24578 2.16954 0.984639 0.903544 0.865358 3.75131 0.962739 1.58134 0.410457 0.90696 1.68435 1.27899 2.15401 0.622187 2.09521 2.29801 4.37366 1.10833 2.42571 2.52263 1.67674 0.673258 2.65618 1.75712 1.33928 1.93758 2.04561 4.89956 0.704984 1.36069 1.62202 2.41526 2.45475 1.82201 2.10493 5.96296 1.01069 0.874158 1.57279 1.69116 1.59813 1.64521 2.69435 0.719034 3.10699 2.05976 2.08718 1.7417 0.795352 2.07426 2.31211 2.08324 0.214443 3.05026 2.47303 1.19769 2.85933 3.10449 1.22681 2.55563 1.17224 2.36616 2.07249 2.19938 1.7058 0.550162 0 2.48319 1.35297 2.21502 1.2626 1.60234 1.79038 1.94509 2.2892 3.05104 1.30441 2.16785 2.23041 4.23673 2.01458 0.567168 2.23768 1.47847 1.56438 1.74966 2.0534 3.66273 3.30105 0.968873 2.96184 1.93494 1.3543 3.48679 2.07331 3.40213 0.866232 2.56462 3.60937 1.3939 4.89379 2.03558 2.25633 2.51501 1.97492 2.46048 0.931274 2.13634 1.12438 1.43701 0.189754 1.25959 0.606015 1.34917 1.58029 2.20553 1.50657 1.89857 0.211654 1.64412 1.08413 1.15675 0.581738 2.18222 0.481598 3.79047 3.89664 2.0494 5.23149 0.308521 3.86416 1.1659 1.44243 1.45634 1.74027 1.26819 3.56491 0.76686 2.03257 0.429684 0.917513 7.76768 1.52584 1.82733 2.36675 1.33196 0.295171 3.55475 3.32693 1.9827 2.28746 3.30306 5.98045 1.62777 2.12296 2.50107 2.83831 0.389987 0.742461 4.6427 1.11395 3.49321 4.28937 1.92072 2.20938 2.65186 0.646903 4.03922 3.64201 1.31433 1.29642 1.85184 6.27118 4.26982 1.65961 4.60528 0.802353 3.89472 2.52515 2.46472 3.66107 2.1833 1.2938 2.40245 1.98815 2.08697 2.41552 1.00163 2.1626 1.82414 2.00497 2.32375 2.45318 2.09484 1.69334 2.62197 1.07337 2.65813 2.1598 1.82612 2.51663 0.833146 2.7731 2.8784 1.44083 0.615122 1.3642 2.43795 1.99094 2.27924 1.90409 2.64875 2.79806 1.42658 3.09276 2.25023 1.76464 2.29542 5.16864 1.19317 1.41655 2.59981 2.71756 3.26903 2.07142 1.21313 2.03328 0.489587 0.642933 0.803888 0.936151 3.03937 1.64424 1.94137 1.5651 0.750926 0.84734 1.36423 2.20857 2.0563 1.93155 2.61601 3.63866 2.30327 2.17831 2.4763 3.24588 2.40015 1.1452 2.20404 3.09773 1.37522 3.16156 4.35871 1.09766 1.8564 0.62867 2.12504 0.45394 1.93093 2.35341 2.41424 3.65532 5.02649 2.71096 0.537016 1.57388 2.68245 1.10873 0.56892 0.588997 3.42841 1.86955 2.37784 1.02962 0.441953 0.686992 4.10238 1.13718 0.77023 1.25173 3.47926 0.920224 1.82975 1.9149 2.6889 2.55606 2.82932 0.785926 2.12882 2.47459 1.69671 1.45083 1.25929 1.4267 2.56408 2.41032 5.25667 1.21722 5.16546 3.27505 2.50323 2.39524 1.86191 1.91433 1.74684 2.19326 0 0 0.253008 0.971797 0.605177 1.88888 0.482194 1.35321 2.94835 0.975843 2.57047 1.53289 2.96109 0.833183 1.39669 2.30554 0.925098 1.36212 2.27405 0.616119 1.51533 0.749562 0.352121 3.38778 5.19809 1.9844 3.24725 0.998779 1.21813 3.19733 3.67277 0 1.75006 2.53142 0.713768 1.38336 0.863699 2.56547 2.30123 6.41887 1.0808 1.62538 1.41241 4.97038 2.83122 2.4668 1.31382 1.43265 2.12699 6.02426 1.31507 1.36911 2.22112 0.759907 3.82798 1.09302 5.6352 1.80164 2.13208 1.52068 1.94272 2.18213 2.17118 2.44366 2.48452 1.76406 4.40561 1.45067 2.0274 2.15808 2.70837 1.74823 2.65027 3.23998 3.4886 2.66344 4.36957 2.15795 4.21705 3.94573 2.37936 1.47871 1.48359 1.14714 2.6817 2.50759 1.70705 6.09182 3.38947 1.75155 3.36816 1.19488 1.27984 1.69858 1.50148 1.07828 2.78961 2.77074 1.37869 0.817367 3.57363 1.39326 0.962776 1.89829 1.85861 2.62705 3.64923 0 3.06053 1.60636 1.16093 2.36415 0.960126 1.4412 1.36497 6.67446 2.72302 2.44504 2.42412 0.791106 4.21711 6.32626 3.31385 1.27356 0.841986 4.18092 3.62968 2.09267 1.35322 4.28364 2.30213 1.80915 6.22781 3.24465 0.685301 1.17573 1.01073 1.44673 1.10528 1.83002 2.60524 2.21683 1.25829 2.77858 3.75082 1.8491 1.55954 4.08368 4.88532 2.87638 1.21924 2.3018 1.81049 2.0643 0.649575 1.20088 1.87388 1.19975 3.28213 0.575138 1.01716 1.21718 4.44548 0.919416 2.50042 4.63241 1.29456 0.847439 1.62037 0.942865 5.48816 0.595335 1.16805 2.63274 1.03237 1.53216 4.43415 4.45403 1.98529 2.92202 0.680136 2.07471 1.50573 1.49468 2.26948 3.89448 3.6684 2.91059 1.15761 0.751523 1.46344 0 1.99586 1.61046 5.25286 2.09844 3.29898 1.37236 1.9134 0.472369 0.917342 3.14644 2.09056 8.04432 5.37396 1.76421 2.19877 1.34663 2.38312 3.75966 0.972812 3.73214 5.5124 1.54288 2.53972 1.15986 5.88229 1.30097 1.64118 1.66967 5.17597 6.66296 4.43775 3.46985 2.82099 4.92896 3.33652 3.22365 0.961691 4.38145 5.03928 2.99947 0 1.68072 2.85103 2.52301 1.97332 3.0338 6.15664 0.62217 2.82047 2.47367 0.872147 3.17552 2.59167 1.62983 1.2837 2.62776 1.88176 2.9005 2.78905 2.29045 2.60005 2.98952 0.832675 2.40907 4.99867 1.27656 0.659996 1.15211 0.499076 0.88139 2.3897 3.78133 1.55443 4.19469 2.14333 5.57176 1.30422 0.168499 2.77605 2.75219 2.67167 4.20257 1.15282 1.3636 1.80493 1.94209 1.82623 4.41009 0.688299 1.98337 4.3188 2.30789 2.31892 3.23531 1.9025 2.77434 0.46154 2.70385 1.3745 1.89379 0.798458 2.0353 1.15629 2.11117 2.17727 1.25024 2.04827 2.17154 1.57284 1.11915 6.29451 3.84189 1.37124 1.52 1.41264 1.29028 1.98386 1.29986 1.88622 2.48038 2.15752 4.62315 2.49986 2.17062 1.61962 1.64608 4.10347 2.68903 1.66838 1.15786 2.79675 3.33209 3.20497 3.39899 1.94416 0.940823 1.67793 1.93814 3.33242 1.16579 1.07032 1.55914 1.41729 1.27303 1.91004 4.74042 0.665309 4.29573 3.25899 2.9692 2.51048 2.1975 1.94341 0.717212 4.97462 4.02124 3.73224 1.61618 0.73268 3.61755 1.68788 2.20795 1.80564 2.50421 1.34723 2.68679 0 3.61796 1.42156 1.86612 2.32227 3.85296 3.30733 1.66771 2.63861 1.97587 1.52988 2.79591 5.69963 2.84239 6.24794 3.09539 0.894521 2.6782 1.31325 3.5741 4.1513 6.23599 2.32203 1.09651 3.27821 1.9869 0.448214 0.952783 2.86931 1.67821 0.932822 1.30109 5.27842 2.99255 5.83775 1.26394 2.8176 1.82133 3.18885 2.9098 3.58103 2.90928 1.35893 1.53131 1.58018 1.63241 1.86109 1.30166 2.4847 1.78239 1.99554 3.20858 2.84224 2.06573 1.73449 1.90756 4.42154 1.90042 2.18108 1.35578 1.38806 1.21388 1.56754 3.58216 1.85289 1.18595 1.04102 1.79329 0.925566 1.15874 1.00749 4.13348 2.44636 2.83451 4.01382 1.33298 1.54978 2.68425 1.42762 0 2.75012 1.38955 2.59881 1.79193 2.16258 1.78823 2.1637 2.55163 1.4725 2.05017 2.16435 1.50449 3.2214 1.45677 0.81616 1.37018 1.2142 1.35448 5.35668 1.12514 2.17703 4.27356 1.52006 3.50225 1.31566 1.91105 3.47979 1.84264 1.91148 2.91649 3.39264 2.1796 4.00841 1.24255 0.950223 3.03256 2.52492 2.98891 1.03686 4.21048 2.39134 2.25463 1.30653 2.14303 3.47644 1.88765 2.32103 2.66332 2.54207 2.10697 2.33215 2.35998 2.31939 2.2425 1.35521 1.91542 2.22665 2.28419 1.48891 1.15133 5.41604 0.829016 3.21266 2.27612 2.58921 3.89066 1.10723 2.58494 3.36844 1.9 2.99662 3.01878 3.79727 0.838978 5.33898 2.09009 0.623588 1.80094 3.39326 1.21053 1.70039 4.1879 1.02047 3.12327 4.10984 3.29489 4.04384 1.07089 1.10968 1.75004 3.54435 0.891186 3.4845 0.988719 2.24761 3.74148 1.64473 1.4987 1.59239 2.3956 2.04844 1.69712 3.65543 2.22688 2.18922 2.58868 1.74642 1.91412 1.87852 1.61872 1.61994 2.00525 3.2748 0.864774 1.35007 5.2688 0.774323 4.08699 2.80784 1.52917 1.67673 0.768349 0.71525 2.17407 2.6085 2.14917 5.10772 1.87199 2.93116 0.835848 2.16784 1.99788 1.59528 2.3254 4.75558 2.51156 1.828 4.43506 4.85236 0.607682 4.01848 4.87545 2.10298 1.54003 4.28833 2.16006 2.27179 4.04625 3.26537 1.66284 2.0619 4.62979 1.41314 1.7693 3.34363 3.66205 1.82763 4.45648 1.14886 5.51016 3.10993 3.05714 2.48175 1.88024 4.48457 1.48554 2.3009 1.1468 1.62319 2.61082 1.89115 1.5412 2.63113 2.81801 2.4428 1.34812 1.91327 1.18685 2.53061 0.932129 2.36093 1.81772 0.905723 2.68833 2.09829 2.92703 1.18927 1.61932 2.89003 4.20542 2.91115 2.63765 2.42636 0.733767 1.0269 4.17707 3.37125 0.776543 2.33324 2.11138 1.56798 1.87658 1.43592 2.86531 2.66531 0.738812 3.25042 3.56339 3.93936 2.43396 3.77875 4.41241 1.36385 2.96143 1.31832 2.7775 1.05309 0.958704 2.02364 3.78037 0 2.52378 2.91667 2.32362 1.22196 0.583178 4.277 1.4805 3.25634 2.82699 2.7912 4.37624 0.973286 5.51143 2.59636 1.91046 4.50638 1.00457 4.09663 2.29846 2.30503 2.11358 6.25481 1.48825 2.74666 4.54713 5.48002 3.31769 1.92738 1.39793 2.28788 1.36713 3.30454 2.71973 2.54453 1.85158 1.15095 4.2015 1.5081 3.48899 2.1091 1.60876 1.47815 5.20856 2.74081 1.4061 3.88138 5.03254 2.66492 4.42125 3.20824 3.9744 1.97375 1.52293 1.13358 2.532 2.71945 1.34133 2.97736 0.92347 1.58611 1.47134 2.57217 4.73747 2.69292 3.28434 0.805128 3.07987 1.16014 2.14195 6.23454 0.936669 0.94085 0.830878 2.67348 1.25859 1.80978 2.49448 2.97053 2.34824 4.27172 1.44087 3.38726 1.83609 1.47167 2.94417 2.08256 6.17208 2.39917 1.26897 2.50775 2.01699 1.77116 3.28324 2.27436 1.38244 3.87433 1.80514 5.46526 2.48006 3.08651 0.900644 1.77431 3.14301 2.86405 1.78709 0.772236 4.31176 1.66852 2.44192 2.50345 1.51349 4.99867 2.19486 0 2.91203 1.25162 4.67012 3.38601 1.8326 3.6405 1.43051 2.69794 1.81954 1.64273 1.73486 2.67655 1.36693 2.36893 5.42355 2.28541 4.27616 1.24882 1.55642 2.12166 3.72087 2.97235 0.726663 2.72496 3.65355 2.56666 2.5153 0.619646 3.50216 0.956927 1.31998 3.3564 3.76638 1.11449 1.88605 1.25419 4.54443 0.810657 1.44103 1.64203 2.47142 1.60951 1.16457 1.95997 1.92471 2.54361 3.35501 2.1722 2.09246 2.77201 3.53906 3.44467 1.45959 ]
@@@ Frame-accuracy per-class: [ 81.0536 68.8525 58.8235 41.5094 70.3297 0 44.898 68.5714 28.3688 77.551 48.8889 46.5753 81.1594 35.443 76.1905 24.2991 50.5747 35.6846 22.2222 82.9268 63.7681 58.6466 5.19481 36.6197 76.5714 48.9796 76.1905 5.6338 55.1724 62.8571 13.8728 8.95522 51.2821 6.15385 90.9091 84.7682 33.8028 66.6667 0 72.1644 47.5825 53.3333 42.5197 63.4686 26.6667 29.5082 42.236 2.03046 60.6742 68.9655 21.0526 17.7778 31.5789 36.3636 65.0602 48.5437 59.5349 84.4037 63.3975 54.321 32.9897 40.8163 84.2788 61.1236 18.6047 70.4225 18.1818 44.7761 76.8612 58.0645 45.8716 56.5657 39.4265 47.8528 82.7586 44.4444 46.1538 95.7746 48.4211 60.3774 40 46.6165 0 75.8621 40.4494 43.1373 16.2162 28.2828 54.7085 34.7826 32.8042 86.8217 56.5517 26.087 46.6165 21.8182 67.6923 50.7463 64.9682 58.8235 12.9032 31.8841 52.6316 58.3026 56 23.1884 50.7937 52.7132 37.3333 69.7674 34.0741 0 21.3904 64.7482 38.2979 0 46.3768 0 24.6154 32 50.9804 28.9855 0 30.7692 77.193 48.2759 12.9032 14.8148 88.8889 56.6038 56.4972 58.8235 40 25.2874 17.9104 60.8 40 86.2944 46.1538 39.2157 13.3333 72.6115 43.4783 38.4 28.5714 96.2963 66.6667 34.6667 19.7802 68.8525 70.6383 76.0563 21.4876 51.9481 53.3333 90.3475 72.7273 51.0638 62.0155 45.6997 67.7966 53.0612 38.0952 0 69.8413 35.8209 34.7826 60.6061 78.0952 15.7303 24.8062 70.5882 48.8889 39.2157 0 73.6842 68.8525 43.4783 40 50.7042 14.8148 24 17.3913 58.8235 76.9231 49.2308 52.6316 43.9024 43.0769 24.7423 86.1538 25.8824 49.5575 57.5342 50.7042 72.2892 32.7273 24.2424 18.1818 94.9153 11.2676 28.5714 72 13.3333 10.5263 54.9451 14.5455 76.0736 37.2093 24.2424 25.641 51.0345 81.3559 0 38.7097 58.156 29.1971 72 41.5094 59.7015 35.6436 56 33.8462 52.6316 36.3636 18.8679 12.766 19.3548 82.7586 38.9105 60.9524 60.1942 50.4202 48.7805 29.2683 23.5294 66.6667 0 22.8571 64.6154 0 36.3636 0 68.3544 31.405 8.69565 72.7273 13.3333 35.8974 34.1463 23.5294 26.6667 28.5714 71.1111 53.3333 64.5161 52.3077 96 48.1013 87.8307 67.5862 51.8519 30.2521 34.2857 54.6763 98.5915 31.3725 69.5652 59.2593 91.8919 41.0256 86.7925 24.4898 10.8787 30.303 0 94.7368 0 66.6667 64.7887 54.0541 39.5062 57.1429 19.1617 76.1905 29.2683 87.8049 70.7692 0 51.2821 32.8358 35.4067 55.6701 92.562 11.3208 23.1579 43.9024 13.7931 18.1818 10.101 44.2478 0 29.2683 20.2899 87.218 80 0 85.7143 37.2093 4.44444 32.2581 29.0909 12.6582 76.9231 0 17.3913 80 66.6667 52.6316 0 0 48.2759 0 67.7686 0 29.8851 26.4151 6.89655 23.5294 57.1429 19.8582 22.2222 19.3548 33.8983 78.2609 36.7041 34.7826 33.8028 35.5556 52.4272 51.1628 45.2174 0 67.5799 25.8065 46.5753 40.678 18.1818 79.0698 39.0244 32.4324 61.5385 84.7162 50.4505 31.6547 50.7042 9.30233 51.1628 31.0078 33.7079 55.6962 13.7931 32.2581 41.8605 40 9.52381 58.0645 59.5745 40 43.1373 27.7228 26.8041 67.9803 50.6667 86.1538 83.2 84.058 71.028 20.5962 65.5462 53.7313 44.898 82.1053 66.6667 45.0704 63.1579 52.8302 41.3793 50.5495 8 34.1463 36.3636 32.8767 15.0538 11.7647 70.4762 35.0877 7.40741 56 28.5714 0 67.7966 54.321 85.9813 29.6296 82.9268 21.0526 44.898 25.731 8.56031 9.21659 27.907 93.3333 53.9326 32.7869 64.6154 88 83.871 0 30.7692 34.2541 57.1429 87.8049 83.0769 26.6667 65.1163 66.5263 57.1429 0 74.4186 45.0116 38.3838 31.3725 32.7869 28.5714 74.5763 48.951 44.4444 55.6522 65.9794 54.8223 68.8172 29.0909 40.9639 0 64.4628 0 0 36.3636 24.7423 69.3069 0 45.6693 48.951 0 0 94.1176 73.6842 86.9565 48.4848 87.0588 65.1685 18.1818 71.3287 10.9091 64.5161 30.303 75.5556 66.6667 17.3913 75.4098 63.7037 45.7831 83.1858 51.6129 70.1754 81.6327 19.7183 26.6667 55.1724 6.45161 75.3623 53.3333 11.7647 20.7792 0 31.5789 35.0877 85.2174 47.5248 72 29.6296 30.3797 7.01754 61.7284 59.7455 50.7042 0 15.3846 10.2564 70.2703 61.8182 48 0 59.0476 42.9752 41.8605 76.3636 0 71.6418 0 48.0447 46.1538 49.3506 47.0588 43.2432 38.835 30.3797 7.54717 8.69565 10.2564 66.6667 42.5532 31.5789 32.4324 31.068 31.4721 16.9014 21.3333 57.1429 20.2899 8.69565 7.07965 15.3565 26.6667 50.6329 60.3175 59.4595 27.907 32.2581 44.898 0 0 58.8235 0 65.1163 71.028 52.1008 65.3061 58.8235 32.2581 22.2222 64.6465 66.6667 27.5862 42.1053 70.5882 28.5714 23.5294 37.2881 5.7971 0 11.7647 54.0541 67.9612 36.1905 78.3505 63.8298 0 0 6.06061 40.8163 25.3521 73.1183 6.06061 3.80952 34.6667 63.4483 57.1429 10.3896 25.2101 45.1613 54.5455 0 48.2759 45.8716 15.2381 30.7692 79.6117 66.6667 82.7586 65.1163 59.2 39.5062 29.8507 36.3636 70.9677 48.6486 10.2564 41.9048 52.3077 7.01754 16 13.5593 48.1928 11.4286 47.619 15.3846 80.6283 48.6486 53.7634 65.4206 11.4286 82.3529 72.7273 64.8649 22.2222 83.871 27.5862 3.63636 40 70.5882 57.1429 53.3333 25.6684 87.7193 55.1724 38.7597 75.5556 70.9677 35.2941 8.24742 59.2593 23.7288 80 38.7097 66.6667 41.5094 41.5584 14.0541 7.40741 23.8532 64.3299 85.7143 48.5207 0 48.8889 52.2523 26.4901 41.4545 0 51.8519 15.3846 97.3913 78.0488 12.1212 45.045 5.84795 0 40 11.9403 57.9439 42.3529 33.1288 63.4731 7.54717 0 60.274 28.8288 69.7674 0 64.6617 60.355 37.8947 0 0 18.5792 11.4943 30.7692 0 34.0426 18.6667 62.8571 10.2564 0 24.4898 0 53.7815 32.7684 37.7358 25.8065 43.9024 0.896861 78.7879 41.5842 26.6667 76.9231 22.2222 0 51.4286 64.5161 28.0702 46.7532 40 29.0909 42.1053 39.1753 7.61905 67.4699 14.0351 0 56.7686 80.5687 61.3333 92.4444 73.5632 22.2222 2.8777 74.2857 9.14286 42.9319 0 65.9341 96.7742 13.3333 32.6531 36.7347 19.8473 57.1429 43.6364 57.6271 34.0136 53.5433 23.1579 80 46.3768 5.40541 26.1682 51.4286 24 57.1429 19.5122 92.3077 20.6897 54.7945 53.5032 73.1707 35.2941 62.069 42.5532 46.3158 46.1538 30.7692 44.4444 0 78.2609 3.35196 0 54.5455 32.4324 48.7805 68.2594 23.5294 58.8235 31.3725 20.2247 61.0169 17.5439 53.3333 41.5094 52.1739 61.2245 10.8844 26.087 46.7836 61.1765 26.6667 2.8169 30.1887 19.7531 45.5696 84.058 46.1538 34.0426 27.027 68.8995 76.3359 63.1579 50.5495 56.4103 37.2093 0 80.4124 14.1176 9.30233 24.6914 49.1228 31.3725 40 76.1905 8.51064 0 0 63.2708 76.1506 0 46.4088 25.4545 51.0638 25.5319 62.3377 35.0515 0 14.0351 61.6541 46.1538 43.956 14.8148 20.4082 13.3333 19.6078 15.3846 48.4848 42.5532 8.16327 33.2046 9.90099 28.9855 79.0698 30.2158 67.6923 20.6897 3.77358 12.1212 27.5862 64.1509 9.52381 25.8065 90.1408 71.8563 16.3265 51.1628 69.9187 52.6316 6.22568 14.1176 19.5489 56.4103 0 39.2157 3.50877 30.1887 13.2231 22.6415 46.5753 59.0164 49.8054 39.6694 35.2941 38.7097 32.6531 40.3361 40 0 15.3846 51.9685 47.0588 35.5556 0 27.1186 22.9508 54.5455 59.542 48 70.5882 19.5122 46.1538 72.7273 70.1031 52.3077 68.5714 72.2689 66.6667 8.16327 18.6047 48.7805 13.3333 79.2453 57.1429 6.45161 64.7887 0 40 64.7887 14.8148 54.2373 20.6897 50.5263 40.404 26.6667 59.2593 0 34.2857 44.4444 25.641 51.9481 83.871 61.6822 71.777 66.6667 7.29927 69.3333 34.0426 15.3846 63.7681 30.5085 40 47.3118 6.48649 65.5738 32.9897 34.9206 0 42.623 24.2424 46.9136 65.3061 40.4494 31.6547 13.7931 76.9231 7.63359 51.6129 13.5593 54.5455 49.1228 25.2788 32.6531 24.3902 34.7826 38.7879 45.0867 40.678 59.2593 32.5581 56 57.1429 44.898 32 33.1288 56.2691 64 3.61757 76.9231 35.0877 32.9114 48.3516 15.873 72.3404 32.8767 30.5344 43.4783 35.443 27.3128 36.0656 60.8696 0 33.4661 81.3187 41.9048 11.5942 64 29.2683 10.1695 66.6667 23.5897 21.1765 13.3333 0 61.5385 68.3544 45.1613 28.3105 69.1589 32.4324 70.5882 32.381 20.8955 47.4576 55.2381 57.1429 37.3626 31.3725 48.3516 19.0476 17.3913 48.9796 32.8358 55.2846 37.7358 45.614 57.6271 50.7042 32.7869 17.9104 81.0811 68.0412 1.76991 84.3931 24.8649 25.5319 56 55.3191 62.069 80 27.5862 27.3973 40.9812 7.94224 49.5868 26.014 74.5098 37.0656 34.9515 55.6962 27.1186 0 48.5981 38.7097 13.7931 7.40741 76.4045 5.19481 16.8675 53.012 70.5882 16.2162 24.6154 36.3636 4.87805 18.6047 45.7143 23.5294 13.4715 36.3636 42.5532 42.8115 15.3846 53.5519 4.65116 46.1538 0 39.1753 11.7647 32.967 57.6271 0 44.4444 34.0426 85.7143 56.4706 28.5714 51.8892 38.0952 41.3793 20.339 23.5294 68.3544 49.6124 68.3544 34.7826 79.2453 28.0702 32.9114 63.2124 29.6296 22.4299 0 63.7681 63.1579 0 18.6047 8.88889 14.0351 24.4898 75.2475 61.5385 0 17.3913 75.5556 25.5319 32.2581 51.8519 59.0164 62.2951 47.5921 16 86.3905 13.6646 12.0482 0 24.1611 21.5385 28.2209 62.069 21.2766 50.9804 32.1168 74.2857 67.0659 47.2727 39.0244 0 29.8507 26.5487 62.069 55.3191 88.5246 0 56.6038 32.5991 0 43.3566 0 64.5161 6.06061 0 38.961 3.25203 76.9231 14.1844 25.3521 35.9551 35.6164 4.84848 32 25.641 7.84314 21.2389 0 16.3265 57.1429 46.4986 73.4694 14.1176 20.4082 20.5128 26.087 65.0602 14.8148 68.4444 17.3913 14.5455 51.2 65.8228 0 26.4151 59.3939 5.12821 0 40.5063 15.6863 25.8065 11.5702 53.6585 55.5102 60.5505 22.5352 40.8163 71.8447 42.1053 73.4694 37.037 54.2936 47.2131 2.53165 25.2101 34.4828 91.7647 33.1984 68.0851 49.1506 0 73.2394 73.9726 70.0353 8.88889 74.6269 44.4444 26.506 18.4615 24.7423 16.8675 58.8235 6.06061 16.2162 61.5385 15.9292 41.0959 10.2857 34.5865 59.7015 42.1053 27.907 32.2581 13.5593 27.2189 66.6667 2.06186 44.2105 0 13.3333 20.6897 75.5556 30.9859 21.5768 21.3198 43.9024 82.3529 15.3005 45.7143 38.7097 31.1111 45.1613 1.68067 30.303 0 10.9091 66.6667 22.2222 10.5263 59.8425 17.2662 42.4242 10.219 21.5385 53.1646 54.3962 38.7097 59.4595 33.8983 3.50877 35.7895 0 63.5294 54.1176 48.2759 0 24.5614 73.3032 25.5319 30.303 21.8182 16 76.7123 19.6078 77.9221 65.1163 10.4348 10.989 64 59.2593 47.0588 0 88.3721 60.2151 53.211 0 58.427 58.5859 30.303 51.6129 37.037 4.12371 18.1818 44.4444 21.3333 8.4507 8 63.7681 ]

LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:347) Done 295 files, 0 with no tgt_mats, 0 with other errors. [CROSS-VALIDATION, 0.0214028 min, fps61683.5]
LOG (nnet-train-multistream-perutt[5.5.1074~1-71f3]:main():nnet-train-multistream-perutt.cc:353) AvgLoss: 1.98886 (Xent), [AvgXent: 1.98886, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 46.7303% <<

WARNING (nnet-train-multistream-perutt[5.5.1074~1-71f3]:Close():kaldi-io.cc:515) Pipe ali-to-pdf exp_FG/tri_8_2000_ali/final.mdl "ark:gunzip -c exp_FG/tri_8_2000_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- | had nonzero return status 36096
